{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directories\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "cache_dir = 'cache'\n",
    "model_dir = 'models'\n",
    "\n",
    "# List of classes\n",
    "classes = ['angry', 'disgusted', 'fearful', 'happy', 'sad', 'surprised', 'neutral']\n",
    "\n",
    "# Number of images in each class\n",
    "print('Number of training images in each class:')\n",
    "for c in classes:\n",
    "    path = os.path.join(train_dir, c)\n",
    "    print(f'{c}: {len(os.listdir(path))} images')\n",
    "    \n",
    "print('\\nNumber of test images in each class:')\n",
    "for c in classes:\n",
    "    path = os.path.join(test_dir, c)\n",
    "    print(f'{c}: {len(os.listdir(path))} images')\n",
    "    \n",
    "# Image size\n",
    "img = cv2.imread('dataset/train/angry/im0.png')\n",
    "print(f'\\nImage size: {img.shape}')\n",
    "\n",
    "# Custom dataset class\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, root_dir, classes, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "        self.file_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for idx, class_name in enumerate(classes):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                self.file_paths.append(os.path.join(class_dir, file_name))\n",
    "                self.labels.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = EmotionDataset(train_dir, classes, transform)\n",
    "test_dataset = EmotionDataset(test_dir, classes, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# Define the CNN model\n",
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(EmotionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.LeakyReLU(0.01)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.LeakyReLU(0.01)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.relu3 = nn.LeakyReLU(0.01)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 512)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.relu4 = nn.LeakyReLU(0.01)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(self.relu3(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(self.relu4(self.bn4(self.fc1(x))))\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = EmotionCNN(num_classes=len(classes))\n",
    "print(\"Model created\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "    print('Finished Training')\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'emotion_recognition_model.pth')\n",
    "print('Model saved as emotion_recognition_model.pth')\n",
    "\n",
    "# Load the model for testing\n",
    "model.load_state_dict(torch.load('emotion_recognition_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Test the model on a single image\n",
    "def predict_emotion(model, img_path, classes, transform):\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        emotion = classes[predicted.item()]\n",
    "        return emotion, output\n",
    "\n",
    "img_path = 'dataset/test/angry/im0.png'\n",
    "emotion, output = predict_emotion(model, img_path, classes, transform)\n",
    "print(f'Predicted emotion: {emotion}')\n",
    "\n",
    "# Display image\n",
    "image = cv2.imread(img_path)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title(f'Predicted emotion: {emotion}')\n",
    "plt.savefig('test_image.png')\n",
    "plt.show()\n",
    "\n",
    "# Display prediction\n",
    "plt.bar(classes, output[0].numpy())\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Emotion prediction')\n",
    "plt.savefig('prediction.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Facial image emotion recognition using CNN\n",
    "# Target classes: Angry, Disgusted, Fearful, Happy, Sad, Surprised, Neutral\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "NUM_THREADS = 32\n",
    "\n",
    "tf.config.threading.set_intra_op_parallelism_threads(NUM_THREADS)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(NUM_THREADS)\n",
    "\n",
    "# Switch to GPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "print(physical_devices)\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "# DATASET\n",
    "# files in dataset/test and dataset/train\n",
    "# subfolders: angry, disgusted, fearful, happy, sad, surprised, neutral\n",
    "\n",
    "# load dataset\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images in each class:\n",
      "angry: 4162 images\n",
      "disgust: 411 images\n",
      "fear: 4172 images\n",
      "happy: 7628 images\n",
      "sad: 5073 images\n",
      "surprise: 2842 images\n",
      "neutral: 5248 images\n",
      "\n",
      "Number of test images in each class:\n",
      "angry: 940 images\n",
      "disgust: 84 images\n",
      "fear: 982 images\n",
      "happy: 1850 images\n",
      "sad: 1270 images\n",
      "surprise: 610 images\n",
      "neutral: 1256 images\n",
      "\n",
      "Image size: (48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "# Check for the number of images in each class and the size of the images\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'  # 0 = alle Meldungen werden ausgegeben\n",
    "\n",
    "# List of classes\n",
    "classes = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "\n",
    "# Number of images in each class\n",
    "print('Number of training images in each class:')\n",
    "for c in classes:\n",
    "    path = os.path.join(train_dir, c)\n",
    "    print(f'{c}: {len(os.listdir(path))} images')\n",
    "    \n",
    "print('\\nNumber of test images in each class:')\n",
    "for c in classes:\n",
    "    path = os.path.join(test_dir, c)\n",
    "    print(f'{c}: {len(os.listdir(path))} images')\n",
    "    \n",
    "# Image size\n",
    "img = cv2.imread('dataset/train/angry/Training_3908.jpg')\n",
    "print(f'\\nImage size: {img.shape}')\n",
    "\n",
    "input_shape = img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m1,799\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,188,007</span> (4.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,188,007\u001b[0m (4.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,399</span> (4.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,187,399\u001b[0m (4.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> (2.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m608\u001b[0m (2.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CNN MODEL\n",
    "input_layer = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "# Erster konventioneller Convolutional Pfad\n",
    "conv1 = tf.keras.layers.Conv2D(16, (3, 3), padding='same')(input_layer)\n",
    "conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "conv1 = tf.keras.layers.ReLU()(conv1)\n",
    "conv1 = tf.keras.layers.MaxPooling2D(2, 2)(conv1)\n",
    "dropout1 = tf.keras.layers.Dropout(0.3)(conv1)\n",
    "\n",
    "# Zweiter konventioneller Convolutional Pfad\n",
    "conv2 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(dropout1)\n",
    "conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "conv2 = tf.keras.layers.ReLU()(conv2)\n",
    "conv2 = tf.keras.layers.MaxPooling2D(2, 2)(conv2)\n",
    "dropout2 = tf.keras.layers.Dropout(0.3)(conv2)\n",
    "\n",
    "# # Dritter konventioneller Convolutional Pfad\n",
    "# conv3 = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(conv2)\n",
    "# conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "# conv3 = tf.keras.layers.LeakyReLU(negative_slope=0.01)(conv3)\n",
    "# conv3 = tf.keras.layers.MaxPooling2D(2, 2)(conv3)\n",
    "\n",
    "# Paralleler Pfad mit Dilated Convolutions\n",
    "# dilated1 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', dilation_rate=3)(input_layer)\n",
    "# dilated1 = tf.keras.layers.BatchNormalization()(dilated1)\n",
    "# dilated1 = tf.keras.layers.LeakyReLU(negative_slope=0.001)(dilated1)\n",
    "# dilated1 = tf.keras.layers.MaxPooling2D(2, 2)(dilated1)\n",
    "# dropout1dilated = tf.keras.layers.Dropout(0.3)(dilated1)\n",
    "\n",
    "# dilated2 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', dilation_rate=3)(dropout1dilated)\n",
    "# dilated2 = tf.keras.layers.BatchNormalization()(dilated2)\n",
    "# dilated2 = tf.keras.layers.LeakyReLU(negative_slope=0.001)(dilated2)\n",
    "# dilated2 = tf.keras.layers.MaxPooling2D(2, 2)(dilated2)\n",
    "# dropout2dilated = tf.keras.layers.Dropout(0.3)(dilated2)\n",
    "\n",
    "# dilated3 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', dilation_rate=4)(dilated2)\n",
    "# dilated3 = tf.keras.layers.BatchNormalization()(dilated3)\n",
    "# dilated3 = tf.keras.layers.LeakyReLU(negative_slope=0.01)(dilated3)\n",
    "# dilated3 = tf.keras.layers.MaxPooling2D(2, 2)(dilated3)\n",
    "\n",
    "# Zusammenführung der Pfade\n",
    "merged = tf.keras.layers.concatenate([dropout2])\n",
    "\n",
    "# Flatten und Dense Layers\n",
    "flat = tf.keras.layers.Flatten()(merged)\n",
    "dense1 = tf.keras.layers.Dense(256)(flat)\n",
    "dense1 = tf.keras.layers.BatchNormalization()(dense1)\n",
    "dense1 = tf.keras.layers.ReLU()(dense1)\n",
    "dropout = tf.keras.layers.Dropout(0.3)(dense1)\n",
    "output = tf.keras.layers.Dense(7, activation='softmax')(dropout)\n",
    "\n",
    "# Modell definieren\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ densenet121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ densenet121 (\u001b[38;5;33mFunctional\u001b[0m)        │ ?                      │     \u001b[38;5;34m7,037,504\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> (26.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,037,504\u001b[0m (26.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,953,856</span> (26.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,953,856\u001b[0m (26.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,648</span> (326.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m83,648\u001b[0m (326.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# DenseNet121 Modell ohne die oberste Klassifikationsschicht laden\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Neue Modellspitze hinzufügen\n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Zusammenfassung des Modells anzeigen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict(np.array([cv2.imread('dataset/train/angry/Training_3908.jpg')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet152v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">58,331,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet152v2 (\u001b[38;5;33mFunctional\u001b[0m)        │ ?                      │    \u001b[38;5;34m58,331,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">58,331,648</span> (222.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m58,331,648\u001b[0m (222.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">58,187,904</span> (221.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m58,187,904\u001b[0m (221.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,744</span> (561.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m143,744\u001b[0m (561.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet152V2\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# ResNet50 Modell ohne die oberste Klassifikationsschicht laden\n",
    "base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Neue Modellspitze hinzufügen\n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Zusammenfassung des Modells anzeigen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the images from disk"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Function to decode and preprocess images\n",
    "def decode_img(img):\n",
    "    img = tf.image.decode_jpeg(img, channels=1)\n",
    "    img = tf.image.resize(img, [48, 48])\n",
    "    img = img / 255.0  # Normalize to [0, 1]\n",
    "    return img\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2]\n",
    "\n",
    "def encode_label(label, label_lookup):\n",
    "    label_id = label_lookup(label)\n",
    "    depth = tf.cast(label_lookup.vocabulary_size(), tf.int32)\n",
    "    return tf.one_hot(label_id, depth=depth)\n",
    "\n",
    "def prepare_label_lookup(train_dir):\n",
    "    file_paths = tf.data.Dataset.list_files(str(pathlib.Path(train_dir) / '*/*'), shuffle=False)\n",
    "    labels = file_paths.map(lambda x: tf.strings.split(x, os.path.sep)[-2])\n",
    "    label_lookup = tf.keras.layers.StringLookup(num_oov_indices=0)\n",
    "    label_lookup.adapt(labels)\n",
    "    return label_lookup\n",
    "\n",
    "# Prepare label lookup\n",
    "label_lookup = prepare_label_lookup(train_dir)\n",
    "\n",
    "def process_path(file_path, label_lookup):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    label = encode_label(label, label_lookup)\n",
    "    label = tf.cast(label, tf.int32)  # Ensure labels are integers\n",
    "    print(f\"Processed label dtype: {label.dtype}\")  # Debugging-Ausgabe\n",
    "    return img, label\n",
    "\n",
    "def augment(img, label):\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_brightness(img, max_delta=0.3)\n",
    "    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n",
    "    print(f\"Augmented label dtype: {label.dtype}\")  # Debugging-Ausgabe\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 09:47:01.344684: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (64, 48, 48, 3), Label dtype: <dtype: 'float32'>\n",
      "Image dtype: <dtype: 'float32'>, Label dtype: <dtype: 'float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 09:47:01.750327: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-07-07 09:47:01.753468: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import dataloader\n",
    "\n",
    "train_ds, test_ds = dataloader.load(train_dir, test_dir)\n",
    "\n",
    "combined_train_ds = train_ds\n",
    "augmented_train_ds = None\n",
    "# Augment dataset\n",
    "# for i in range(0):\n",
    "#     augmented_train_ds = train_ds.map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "#     # Combine original and augmented datasets\n",
    "#     combined_train_ds = combined_train_ds.concatenate(augmented_train_ds)\n",
    "\n",
    "# Shuffle, batch, and prefetch\n",
    "combined_train_ds = combined_train_ds.shuffle(512).batch(64).prefetch(tf.data.experimental.AUTOTUNE).cache()\n",
    "test_ds = test_ds.batch(64).prefetch(tf.data.experimental.AUTOTUNE).cache()\n",
    "\n",
    "# Print one image (to confirm whether the images are represented as 48x48x1 tensors)\n",
    "for img, label in combined_train_ds.take(1):\n",
    "    print(f\"Image shape: {img.shape}, Label dtype: {label.dtype}\")\n",
    "    print(f\"Image dtype: {img.dtype}, Label dtype: {label.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print one image (to confirm whether the images are represented as 48x48x1 tensors)\n",
    "#for img, label in augmented_train_ds.take(1):\n",
    "#    print(f\"Image shape: {img.shape}, Label dtype: {label.dtype}\")\n",
    "#    print(f\"Image dtype: {img.dtype}, Label dtype: {label.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 09:48:13.841576: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'label_lookup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Eine Stichprobe aus dem Trainingsdatensatz anzeigen\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_batch, label_batch \u001b[38;5;129;01min\u001b[39;00m combined_train_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m     show_batch(image_batch, label_batch, \u001b[43mlabel_lookup\u001b[49m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_batch, label_batch \u001b[38;5;129;01min\u001b[39;00m test_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     18\u001b[0m     show_batch(image_batch, label_batch, label_lookup)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_lookup' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_batch(image_batch, label_batch, label_lookup):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5, 5, n + 1)\n",
    "        # Show image as grayscale\n",
    "        plt.imshow(tf.squeeze(image_batch[n]), cmap='gray')\n",
    "        label = label_lookup.get_vocabulary()[tf.argmax(label_batch[n]).numpy()]\n",
    "        plt.title(label)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "# Eine Stichprobe aus dem Trainingsdatensatz anzeigen\n",
    "for image_batch, label_batch in combined_train_ds.take(1):\n",
    "    show_batch(image_batch, label_batch, label_lookup)\n",
    "\n",
    "for image_batch, label_batch in test_ds.take(1):\n",
    "    show_batch(image_batch, label_batch, label_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 09:48:14.379421: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Class Distribution: Counter({0: 1850, 2: 1270, 1: 1255, 3: 982, 4: 939, 5: 610, 6: 84})\n",
      "Test Class Distribution: Counter({0: 7628, 1: 5248, 2: 5073, 3: 4171, 4: 4162, 5: 2842, 6: 411})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 09:48:15.217792: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "def get_class_distribution(dataset):\n",
    "    class_counts = collections.Counter()\n",
    "    \n",
    "    for _, label_batch in dataset:\n",
    "        labels = tf.argmax(label_batch, axis=1)\n",
    "        class_counts.update(labels.numpy())\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "# Klassenverteilung im Trainingsdatensatz\n",
    "train_class_distribution = get_class_distribution(combined_train_ds)\n",
    "print(\"Train Class Distribution:\", train_class_distribution)\n",
    "\n",
    "# Klassenverteilung im Testdatensatz\n",
    "test_class_distribution = get_class_distribution(test_ds)\n",
    "print(\"Test Class Distribution:\", test_class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Load test data\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i, c in enumerate(classes):\n",
    "    path = os.path.join(train_dir, c)\n",
    "    for img_name in os.listdir(path):\n",
    "        # img = cv2.imread(os.path.join(path, img_name))\n",
    "        if img is not None:  # Ensure the image was read correctly\n",
    "            # img = cv2.resize(img, (48, 48))\n",
    "            # x_train.append(img)\n",
    "            y_train.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 09:48:15.981101: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(set(y_train))\n",
    "plt.hist(y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1.0137639870941169, 1: 10.265901981230448, 2: 1.0115765318354626, 3: 0.5531313206981796, 4: 0.8317141167525556, 5: 1.4846184779330451, 6: 0.8039797473867596}\n",
      "Type of keys: <class 'int'>\n",
      "Type of values: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "y_train_encoded = tf.keras.utils.to_categorical(y_train, num_classes=7)\n",
    "\n",
    "# Nehme an, y_train_labels sind die Labels deiner Trainingsdaten\n",
    "y_train_labels = np.argmax(y_train_encoded, axis=1)\n",
    "y_train_labels = y_train_labels.astype(np.int32)\n",
    "\n",
    "# Berechnung der Klassengewichte\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                  classes=np.unique(y_train_labels),\n",
    "                                                  y=y_train_labels)\n",
    "\n",
    "# Convert the class weights to a dictionary. Use np.int32 as the key type\n",
    "class_weights_dict = {int(k): float(v) for k, v in zip(np.unique(y_train_labels), class_weights)}\n",
    "\n",
    "print(\"Class weights:\", class_weights_dict)\n",
    "# Print the type of keys in the dictionary\n",
    "print(\"Type of keys:\", type(list(class_weights_dict.keys())[0]))\n",
    "# Print the type of values in the dictionary\n",
    "print(\"Type of values:\", type(list(class_weights_dict.values())[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback functions\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, mode='min')\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0. 0. 0. 1. 0. 0.], shape=(7,), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 09:48:16.493503: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(1):  # Only take the first batch\n",
    "    print(label)  # Show the label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m 72/110\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 1s/step - accuracy: 0.5503 - loss: 1.4831"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    combined_train_ds,\n",
    "    # class_weight=class_weights_dict,\n",
    "    epochs=5,\n",
    "    validation_data=test_ds,\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history (loss and accuracy)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i, c in enumerate(classes):\n",
    "    path = os.path.join(test_dir, c)\n",
    "    for img_name in os.listdir(path):\n",
    "        img = cv2.imread(os.path.join(path, img_name))\n",
    "        if img is not None:  # Ensure the image was read correctly\n",
    "            img = cv2.resize(img, (48, 48))\n",
    "            # Image to greyscale and shape (48, 48, 1)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            x_test.append(img)\n",
    "            y_test.append(i)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Bruh, why you taking so long..\n",
    "\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test, num_classes=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if history is not None:\n",
    "\n",
    "    # PLOT TRAINING AND VALIDATION ACCURACY\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    # PLOT TRAINING AND VALIDATION LOSS\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    # Zugreifen auf die Metriken im Trainingsverlauf\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    precision = history.history['precision']\n",
    "    val_precision = history.history['val_precision']\n",
    "    recall = history.history['recall']\n",
    "    val_recall = history.history['val_recall']\n",
    "\n",
    "    # Beispielausgabe der Genauigkeit\n",
    "    print(\"Training Accuracy:\", accuracy)\n",
    "    print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "\n",
    "# SAVE MODEL, if model is defined\n",
    "\n",
    "if model is not None: \n",
    "    model.save('emotion_recognition_model.h5')\n",
    "    print('Model saved as emotion_recognition_model.h5')\n",
    "else:\n",
    "    # Load model\n",
    "    model = tf.keras.models.load_model('emotion_recognition_model.h5')\n",
    "    print('Model loaded from emotion_recognition_model.h5')\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluate model\n",
    "# Evaluiere das Modell\n",
    "evaluation = model.evaluate(x_test, y_test_encoded)\n",
    "\n",
    "# Evaluationsergebnisse anzeigen\n",
    "print(evaluation)\n",
    "\n",
    "# Predict test data\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Normalized Confusion Matrix:\\n\", cm_normalized)\n",
    "\n",
    "# Display normalized confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', xticklabels=classes, yticklabels=classes, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# TEST MODEL\n",
    "# Load test image\n",
    "file_path = 'dataset/test/angry/PrivateTest_88305.jpg'\n",
    "img = x_test[0]\n",
    "print(f'Image shape: {img.shape}')\n",
    "\n",
    "# Display image\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "img = np.reshape(img, [1, 48, 48, 1])\n",
    "img = img / 255.0  # Normalize to [0, 1]\n",
    "# Predict emotion\n",
    "prediction = model.predict(img)\n",
    "emotion = classes[np.argmax(prediction)]\n",
    "print(f'Predicted emotion: {emotion}')\n",
    "\n",
    "# Display prediction\n",
    "plt.bar(classes, prediction[0])\n",
    "plt.ylabel('Probability')\n",
    "plt.show()\n",
    "\n",
    "# 5x5 matrix with random pictures from the test set, labeled with the predicted emotion and the true emotion; text color is green if the prediction is correct, red otherwise\n",
    "import random\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    index = random.randint(0, len(x_test) - 1)\n",
    "    img = x_test[index]\n",
    "    img = np.reshape(img, [1, 48, 48, 1])\n",
    "    img = img / 255.0  # Normalize to [0, 1]\n",
    "    prediction = model.predict(img)\n",
    "    emotion = classes[np.argmax(prediction)]\n",
    "    true_emotion = classes[y_test[index]]\n",
    "    color = 'g' if emotion == true_emotion else 'r'\n",
    "    plt.imshow(cv2.cvtColor(x_test[index], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Pred: {emotion}\\nTrue: {true_emotion}', color=color)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
